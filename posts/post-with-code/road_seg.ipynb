{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Road_segmantation\"\n",
    "date: \"2024-06-25\"\n",
    "categories: [code, analysis]\n",
    "image: \"image.jpg\"\n",
    "---\n",
    "\n",
    "This is a post with executable code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datasets\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "#Utils\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "#ConfusionMatrix\n",
    "import numpy as np\n",
    "\n",
    "#Loss\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Train\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KariRoadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, train=False):\n",
    "        self.root = Path(root)\n",
    "        self.train = train\n",
    "        if train:\n",
    "            self.img_dir = self.root/'train'/'images'\n",
    "        else:\n",
    "            self.img_dir = self.root/'val'/'images'\n",
    "        self.img_files = sorted(self.img_dir.glob('*.png'))\n",
    "        self.transform = get_transforms(train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_file= self.img_files[idx].as_posix()\n",
    "        label_file = img_file.replace('images', 'labels')\n",
    "        img = cv2.imread(img_file)\n",
    "        label = cv2.imread(label_file, cv2.IMREAD_GRAYSCALE)\n",
    "        img, label = self.transform(img, label)\n",
    "        return img, label, img_file\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "    \n",
    "class ImageAug:\n",
    "    def __init__(self, train):\n",
    "        if train:\n",
    "            self.aug = A.Compose([A.RandomCrop(256, 256),\n",
    "                                  A.HorizontalFlip(p=0.5),\n",
    "                                  A.ShiftScaleRotate(p=0.3),\n",
    "                                  A.RandomBrightnessContrast(p=0.3),\n",
    "                                  A.pytorch.transforms.ToTensorV2()])\n",
    "        else:\n",
    "            self.aug = ToTensorV2()\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        transformed = self.aug(image=img, mask=np.squeeze(label))\n",
    "        return transformed['image']/255.0, transformed['mask']\n",
    "\n",
    "def get_transforms(train):\n",
    "    transforms = ImageAug(train)\n",
    "    return transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_file(img_file):\n",
    "    img = cv2.imread(img_file)\n",
    "    output_file = os.path.join('outputs', os.path.basename(img_file))\n",
    "    cv2.imwrite(output_file, img)\n",
    "\n",
    "\n",
    "def make_color_label_file(label_file):\n",
    "    label = cv2.imread(label_file, cv2.IMREAD_GRAYSCALE)  # (H, W) shape\n",
    "    h, w = label.shape\n",
    "    color_label = np.zeros((h, w, 3), dtype=np.uint8)  # (H, W, 3) shape\n",
    "    colors = [\n",
    "        [0, 0, 0],          # 0: background\n",
    "        [144, 124, 226],    # 1: motorway\n",
    "        [172, 192, 251],    # 2: trunk\n",
    "        [161, 215, 253],    # 3: primary\n",
    "        [187, 250, 246],    # 4: secondary\n",
    "        [255, 255, 255],    # 5: tertiary\n",
    "        [49, 238, 75],      # 6: path\n",
    "        [173, 173, 173],    # 7: under construction\n",
    "        [255, 85, 170],     # 8: train guideway\n",
    "        [234, 232, 120]     # 9: airplay runway\n",
    "    ]\n",
    "    for i in range(10):\n",
    "        color_label[label == i] = colors[i]\n",
    "    return color_label\n",
    "\n",
    "\n",
    "def make_color_label(label):\n",
    "    h, w = label.shape\n",
    "    color_label = np.zeros((h, w, 3), dtype=np.uint8)  # (H, W, 3) shape\n",
    "    colors = [\n",
    "        [0, 0, 0],          # 0: background\n",
    "        [144, 124, 226],    # 1: motorway\n",
    "        [172, 192, 251],    # 2: trunk\n",
    "        [161, 215, 253],    # 3: primary\n",
    "        [187, 250, 246],    # 4: secondary\n",
    "        [255, 255, 255],    # 5: tertiary\n",
    "        [49, 238, 75],      # 6: path\n",
    "        [173, 173, 173],    # 7: under construction\n",
    "        [255, 85, 170],     # 8: train guideway\n",
    "        [234, 232, 120]     # 9: airplay runway\n",
    "    ]\n",
    "    for i in range(10):\n",
    "        color_label[label == i] = colors[i]\n",
    "    return color_label\n",
    "\n",
    "\n",
    "def plot_image_label_file(img_file, alpha=0.3):\n",
    "    img = cv2.imread(img_file)\n",
    "    label_file = img_file.replace('images', 'labels')\n",
    "    color_label = make_color_label_file(label_file)\n",
    "    overlay = cv2.addWeighted(img, 1, color_label, alpha, 0)\n",
    "    output_file = os.path.join('outputs', os.path.basename(img_file).replace('.png', '_overlay.png'))\n",
    "    cv2.imwrite(output_file, overlay)\n",
    "\n",
    "\n",
    "def plot_image(img, label=None, save_file='image.png', alpha=0.3):\n",
    "    # if img is tensor, convert to cv2 image\n",
    "    if torch.is_tensor(img):\n",
    "        img = img.mul(255.0).cpu().numpy().transpose(1, 2, 0).astype(np.uint8)\n",
    "\n",
    "    if label is not None:\n",
    "        # if label_img is tensor, convert to cv2 image\n",
    "        if torch.is_tensor(label):\n",
    "            label = label.cpu().numpy().astype(np.uint8)\n",
    "            color_label = make_color_label(label)\n",
    "            label = color_label\n",
    "        else:\n",
    "            color_label = make_color_label(label)\n",
    "            label = color_label\n",
    "        # overlay images\n",
    "        img = cv2.addWeighted(img, 1.0, label, alpha, 0)\n",
    "    # save image\n",
    "    cv2.imwrite(save_file, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrix:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.confusion_matrix = np.zeros((num_classes, num_classes))\n",
    "        # self.confusion_matrix_torch = torch.zeros((num_classes, num_classes))\n",
    "\n",
    "    def process_batch(self, preds, targets):\n",
    "        preds = preds.argmax(1).cpu().numpy().flatten()\n",
    "        targets = targets.cpu().numpy().flatten()\n",
    "        mask = (targets >= 0) & (targets < self.num_classes)\n",
    "        \n",
    "        confusion_mtx = np.bincount(self.num_classes * targets[mask].astype(int) + preds[mask],\n",
    "                        minlength=self.num_classes ** 2)\n",
    "        confusion_mtx = confusion_mtx.reshape(self.num_classes, self.num_classes)\n",
    "        self.confusion_matrix += confusion_mtx\n",
    "\n",
    "    def print(self):\n",
    "        for i in range(self.num_classes):\n",
    "            print(f\"Class {i}: {self.confusion_matrix[i, i]} / {self.confusion_matrix[i].sum()}\")\n",
    "\n",
    "    def get_pix_acc(self):\n",
    "        return np.diag(self.confusion_matrix).sum() / self.confusion_matrix.sum()\n",
    "\n",
    "    def get_class_acc(self):\n",
    "        class_acc = np.diag(self.confusion_matrix) / self.confusion_matrix.sum(axis=1)\n",
    "        return np.nanmean(class_acc)\n",
    "    \n",
    "    def get_iou(self):\n",
    "        divisor = self.confusion_matrix.sum(axis=1) + self.confusion_matrix.sum(axis=0) - \\\n",
    "                    np.diag(self.confusion_matrix)\n",
    "        iou = np.diag(self.confusion_matrix) / divisor\n",
    "        return iou\n",
    "    \n",
    "    def get_mean_iou(self):\n",
    "        iou = self.get_iou()\n",
    "        return np.nansum(iou) / self.num_classes\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bce_loss(preds, targets, pos_weight=None):\n",
    "    \"\"\"Computes the weighted binary cross-entropy loss.\n",
    "    Args:\n",
    "        targets: a tensor of shape [B, 1, H, W].\n",
    "        preds: a tensor of shape [B, 1, H, W]\n",
    "    Returns:\n",
    "        bce_loss: the weighted binary cross-entropy loss.\n",
    "    \"\"\"\n",
    "    bce_loss = F.binary_cross_entropy_with_logits(\n",
    "        preds.float(),\n",
    "        targets.float(),\n",
    "        pos_weight=pos_weight,\n",
    "    )\n",
    "    return bce_loss\n",
    "\n",
    "\n",
    "def ce_loss(preds, targets, ignore=255):\n",
    "    \"\"\"Computes the weighted multi-class cross-entropy loss.\n",
    "    Args:\n",
    "        targets: a tensor of shape [B, H, W].\n",
    "        preds: a tensor of shape [B, C, H, W]. \n",
    "        ignore: the class index to ignore.\n",
    "    Returns:\n",
    "        ce_loss: the weighted multi-class cross-entropy loss.\n",
    "    \"\"\"\n",
    "    ce_loss = F.cross_entropy(\n",
    "        preds.float(),\n",
    "        targets.long(),    # [B, H, W]\n",
    "        ignore_index=ignore,\n",
    "    )\n",
    "    return ce_loss\n",
    "\n",
    "\n",
    "def dice_loss(preds, targets, eps=1e-7):\n",
    "    \"\"\"Computes the Sørensen–Dice loss.\n",
    "    Args:\n",
    "    preds(logits) a tensor of shape [B, C, H, W]\n",
    "    targets: a tensor of shape [B, 1, H, W].\n",
    "    eps: added to the denominator for numerical stability.\n",
    "    Returns:\n",
    "        dice_loss: the Sørensen–Dice loss.\n",
    "    \"\"\"\n",
    "    num_classes = preds.shape[1]\n",
    "    true_1_hot = F.one_hot(targets.squeeze(1), num_classes=num_classes)   # (B, 1, H, W) to (B, H, W, C)\n",
    "    true_1_hot = true_1_hot.permute(0, 3, 1, 2)                        # (B, H, W, C) to (B, C, H, W)\n",
    "    probas = F.softmax(preds, dim=1)\n",
    "    true_1_hot = true_1_hot.type(preds.type()).contiguous()\n",
    "    dims = (0,) + tuple(range(2, targets.ndimension()))        # dims = (0, 2, 3)\n",
    "    intersection = torch.sum(probas * true_1_hot, dims)     # intersection w.r.t. the class\n",
    "    cardinality = torch.sum(probas + true_1_hot, dims)      # cardinality w.r.t. the class\n",
    "    dice_loss = (2. * intersection / (cardinality + eps)).mean()\n",
    "    return (1 - dice_loss)\n",
    "\n",
    "\n",
    "def jaccard_loss(preds, targets, eps=1e-7):\n",
    "    \"\"\"Computes the Jaccard loss.\n",
    "    Args:\n",
    "    preds(logits) a tensor of shape [B, C, H, W]\n",
    "    targets: a tensor of shape [B, 1, H, W].\n",
    "    eps: added to the denominator for numerical stability.\n",
    "    Returns:\n",
    "        Jaccard loss\n",
    "    \"\"\"\n",
    "    num_classes = preds.shape[1]\n",
    "    true_1_hot = F.one_hot(targets.squeeze(1), num_classes=num_classes)  # (B, 1, H, W) to (B, H, W, C)\n",
    "    true_1_hot = true_1_hot.permute(0, 3, 1, 2)  # (B, H, W, C) to (B, C, H, W)\n",
    "    probas = F.softmax(preds, dim=1)\n",
    "    true_1_hot = true_1_hot.type(preds.type()).contiguous()\n",
    "    dims = (0,) + tuple(range(2, targets.ndimension()))\n",
    "    intersection = torch.sum(probas * true_1_hot, dims)\n",
    "    cardinality = torch.sum(probas + true_1_hot, dims)\n",
    "    union = cardinality - intersection\n",
    "    jacc_loss = (intersection / (union + eps)).mean()\n",
    "    return (1 - jacc_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one_epoch( train, val )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(train_dataloader, model, optimizer, device):\n",
    "    model.train()\n",
    "    losses = [] \n",
    "    for i, (imgs, targets, _) in enumerate(train_dataloader):\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "        preds = model(imgs)['out']     # forward \n",
    "        loss = ce_loss(preds, targets) # calculates the iteration loss  \n",
    "        optimizer.zero_grad()   # zeros the parameter gradients\n",
    "        loss.backward()         # backward\n",
    "        optimizer.step()        # update weights\n",
    "        print('\\t iteration: %d/%d, loss=%.4f' % (i, len(train_dataloader)-1, loss))    \n",
    "        losses.append(loss.item())\n",
    "    return torch.tensor(losses).mean().item()\n",
    "\n",
    "\n",
    "def val_one_epoch(val_dataloader, model, confusion_matrix, device):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    total = 0\n",
    "    for i, (imgs, targets, img_file) in enumerate(val_dataloader):\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "        with torch.no_grad():\n",
    "            preds = model(imgs)['out']   # forward, preds: (B, 2, H, W)\n",
    "            loss = ce_loss(preds, targets)\n",
    "            losses.append(loss.item())\n",
    "            confusion_matrix.process_batch(preds, targets)\n",
    "            total += preds.size(0)\n",
    "            # sample images\n",
    "            if i == 0:\n",
    "                preds = torch.argmax(preds, axis=1) # (1, H, W)  \n",
    "                for j in range(3):\n",
    "                    save_file = os.path.join('outputs', 'val_%d.png' % (j))\n",
    "                    plot_image(imgs[j], preds[j], save_file)\n",
    "                \n",
    "    avg_loss = torch.tensor(losses).mean().item()\n",
    "    \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=200, batch_size = 8 , name = 'suwany'):\n",
    "    # wandb settings\n",
    "    wandb.init(id=name, resume='allow', mode='disabled')\n",
    "    wandb.config.update({\n",
    "        'epochs': epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'name': name\n",
    "    })\n",
    "    \n",
    "    # Train dataset\n",
    "    train_dataset = KariRoadDataset('./data/kari-road', train=True)\n",
    "    # Train dataloader\n",
    "    num_workers = min([os.cpu_count(), batch_size, 16])\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                            shuffle=True, num_workers=num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # Validation dataset\n",
    "    val_dataset = KariRoadDataset('./data/kari-road', train=False)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, \n",
    "                            shuffle=True, num_workers=num_workers, pin_memory=True, drop_last=False)\n",
    "    \n",
    "    # Network model\n",
    "    num_classes = 10 # background + 1 classes\n",
    "    model = models.segmentation.deeplabv3_resnet101(num_classes=num_classes)  \n",
    "    \n",
    "    # GPU-support\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if torch.cuda.device_count() > 1:   # multi-GPU\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "      \n",
    "    # Learning rate scheduler\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "    # loading a weight file (if exists)\n",
    "    weight_file = Path('weights')/(name + '.pth')\n",
    "    best_accuracy = 0.0\n",
    "    start_epoch, end_epoch = (0, epochs)\n",
    "    if os.path.exists(weight_file):\n",
    "        checkpoint = torch.load(weight_file)\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_accuracy = checkpoint['best_accuracy']\n",
    "        print('resumed from epoch %d' % start_epoch)\n",
    "    \n",
    "    \n",
    "    confusion_matrix = ConfusionMatrix(num_classes)\n",
    " # training/validation\n",
    "    for epoch in range(start_epoch, end_epoch):\n",
    "        print('epoch: %d/%d' % (epoch, end_epoch-1))\n",
    "        t0 = time.time()\n",
    "        # training\n",
    "        epoch_loss = train_one_epoch(train_dataloader, model, optimizer, device)\n",
    "        t1 = time.time()\n",
    "        print('loss=%.4f (took %.2f sec)' % (epoch_loss, t1-t0))\n",
    "        lr_scheduler.step(epoch_loss)\n",
    "        # validation\n",
    "        val_epoch_loss = val_one_epoch(val_dataloader, model, confusion_matrix, device)\n",
    "        val_epoch_iou = confusion_matrix.get_iou()\n",
    "        val_epoch_mean_iou = confusion_matrix.get_mean_iou()\n",
    "        val_epoch_pix_accuracy = confusion_matrix.get_pix_acc()\n",
    "        \n",
    "        print('[validation] loss=%.4f, mean iou=%.4f, pixel accuracy=%.4f' % \n",
    "              (val_epoch_loss, val_epoch_mean_iou, val_epoch_pix_accuracy))\n",
    "        print('class IoU: [' + ', '.join([('%.4f' % (x)) for x in val_epoch_iou]) + ']')\n",
    "        # saving the best status into a weight file\n",
    "        if val_epoch_pix_accuracy > best_accuracy:\n",
    "             best_weight_file = Path('weights')/(name + '_best.pth')\n",
    "             best_accuracy = val_epoch_pix_accuracy\n",
    "             state = {'model': model.state_dict(), 'epoch': epoch, 'best_accuracy': best_accuracy}\n",
    "             torch.save(state, best_weight_file)\n",
    "             print('best accuracy=>saved\\n')\n",
    "        # saving the current status into a weight file\n",
    "        state = {'model': model.state_dict(), 'epoch': epoch, 'best_accuracy': best_accuracy}\n",
    "        torch.save(state, weight_file)\n",
    "        # wandb logging\n",
    "        wandb.log({'train_loss': epoch_loss, 'val_loss': val_epoch_loss, 'val_accuracy': val_epoch_pix_accuracy})\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실행 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0/199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:SEND Error: Host unreachable\n"
     ]
    }
   ],
   "source": [
    "train(epochs=200, batch_size = 8 , name = 'suwany')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
