{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Road_segmantation\"\n",
    "date: \"2024-06-25\"\n",
    "categories: [code, analysis]\n",
    "image: \"image.jpg\"\n",
    "---\n",
    "\n",
    "This is a post with executable code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datasets\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "#Utils\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "#ConfusionMatrix\n",
    "import numpy as np\n",
    "\n",
    "#Loss\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Train\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KariRoadDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, train=False):\n",
    "        self.root = Path(root)\n",
    "        self.train = train\n",
    "        if train:\n",
    "            self.img_dir = self.root/'train'/'images'\n",
    "        else:\n",
    "            self.img_dir = self.root/'val'/'images'\n",
    "        self.img_files = sorted(self.img_dir.glob('*.png'))\n",
    "        self.transform = get_transforms(train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_file= self.img_files[idx].as_posix()\n",
    "        label_file = img_file.replace('images', 'labels')\n",
    "        img = cv2.imread(img_file)\n",
    "        label = cv2.imread(label_file, cv2.IMREAD_GRAYSCALE)\n",
    "        img, label = self.transform(img, label)\n",
    "        return img, label, img_file\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "    \n",
    "class ImageAug:\n",
    "    def __init__(self, train):\n",
    "        if train:\n",
    "            self.aug = A.Compose([A.RandomCrop(256, 256),\n",
    "                                  A.HorizontalFlip(p=0.5),\n",
    "                                  A.ShiftScaleRotate(p=0.3),\n",
    "                                  A.RandomBrightnessContrast(p=0.3),\n",
    "                                  A.pytorch.transforms.ToTensorV2()])\n",
    "        else:\n",
    "            self.aug = ToTensorV2()\n",
    "\n",
    "    def __call__(self, img, label):\n",
    "        transformed = self.aug(image=img, mask=np.squeeze(label))\n",
    "        return transformed['image']/255.0, transformed['mask']\n",
    "\n",
    "def get_transforms(train):\n",
    "    transforms = ImageAug(train)\n",
    "    return transforms"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "::: {.panel-tabset}\n",
    "\n",
    "### <span style=\"color:purple\">KariRoadDataset</span>\n",
    "\n",
    "::: {.panel-tabset}\n",
    "\n",
    "\n",
    "### <span style=\"color:sky\"> __init__ </span>\n",
    "\n",
    "``` yaml\n",
    "def __init__(self, root, train=False):\n",
    "        self.root = Path(root)\n",
    "        self.train = train\n",
    "        if train:\n",
    "            self.img_dir = self.root/'train'/'images'\n",
    "        else:\n",
    "            self.img_dir = self.root/'val'/'images'\n",
    "        self.img_files = sorted(self.img_dir.glob('*.png'))\n",
    "        self.transform = get_transforms(train)\n",
    "```\n",
    "__init__ ë©”ì†Œë“œëŠ” í´ë˜ìŠ¤ê°€ ì´ˆê¸°í™”ë  ë•Œ<br> \n",
    " í•™ìŠµ ì—¬ë¶€ì— ë”°ë¼ ë°ì´í„°ì…‹ì˜ ë£¨íŠ¸ ê²½ë¡œì™€ë¥¼ ì„¤ì •í•˜ê³ ,  \n",
    "ì´ ì •ë³´ë“¤ì„ í´ë˜ìŠ¤ ë‚´ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "### <span style=\"color:sky\">__getitem__</span>\n",
    "\n",
    "``` yaml\n",
    "def __getitem__(self, idx):\n",
    "    img_file= self.img_files[idx].as_posix()\n",
    "    label_file = img_file.replace('images', 'labels')\n",
    "    img = cv2.imread(img_file)\n",
    "    label = cv2.imread(label_file, cv2.IMREAD_GRAYSCALE)\n",
    "    img, label = self.transform(img, label)\n",
    "    return img, label, img_file\n",
    "```\n",
    "### <span style=\"color:sky\">__len__</span>\n",
    "\n",
    "``` yaml\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "```\n",
    "\n",
    ":::\n",
    "### <span style=\"color:purple\">ImageAug</span>\n",
    "\n",
    "::: {.panel-tabset}\n",
    "\n",
    "### <span style=\"color:sky\">__init__</span>\n",
    "\n",
    "``` yaml\n",
    "def __init__(self, train):\n",
    "    if train:\n",
    "        self.aug = A.Compose([A.RandomCrop(256, 256),\n",
    "                                A.HorizontalFlip(p=0.5),\n",
    "                                A.ShiftScaleRotate(p=0.3),\n",
    "                                A.RandomBrightnessContrast(p=0.3),\n",
    "                                A.pytorch.transforms.ToTensorV2()])\n",
    "    else:\n",
    "        self.aug = ToTensorV2()\n",
    "```\n",
    "### <span style=\"color:sky\">__call__</span>\n",
    "\n",
    "``` yaml\n",
    "def __call__(self, img, label):\n",
    "    transformed = self.aug(image=img, mask=np.squeeze(label))\n",
    "    return transformed['image']/255.0, transformed['mask']\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    ":::\n",
    "### <span style=\"color:red\">get_transforms</span>\n",
    "\n",
    "``` yaml\n",
    "def get_transforms(train):\n",
    "    transforms = ImageAug(train)\n",
    "    return transforms\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_color_label(label):\n",
    "    h, w = label.shape\n",
    "    color_label = np.zeros((h, w, 3), dtype=np.uint8)  # (H, W, 3) shape\n",
    "    colors = [\n",
    "        [0, 0, 0],          # 0: background ë°°ê²½ (ê²€ì€ìƒ‰)\n",
    "        [144, 124, 226],    # 1: motorway ê³ ì†ë„ë¡œ (ë³´ë¼ìƒ‰)\n",
    "        [172, 192, 251],    # 2: trunk ê°„ì„ ë„ë¡œ (ì—°í•œ íŒŒë€ìƒ‰)\n",
    "        [161, 215, 253],    # 3: primary ì£¼ìš”ë„ë¡œ (ì—°í•œ í•˜ëŠ˜ìƒ‰)\n",
    "        [187, 250, 246],    # 4: secondary ë¶€ì°¨ì ì¸ ë„ë¡œ (ì—°í•œ ë¯¼íŠ¸ìƒ‰)\n",
    "        [255, 255, 255],    # 5: tertiary 3ì°¨ ë„ë¡œ (í°ìƒ‰)\n",
    "        [49, 238, 75],      # 6: path ê²½ë¡œ (ë…¹ìƒ‰)\n",
    "        [173, 173, 173],    # 7: under construction ê±´ì„¤ ì¤‘ (íšŒìƒ‰)\n",
    "        [255, 85, 170],     # 8: train guideway ê¸°ì°¨ ì•ˆë‚´ë¡œ (ë¶„í™ìƒ‰)\n",
    "        [234, 232, 120]     # 9: airplay runway ë¹„í–‰ê¸° í™œì£¼ë¡œ (ë…¸ë€ìƒ‰)\n",
    "    ]\n",
    "    for i in range(10):\n",
    "        color_label[label == i] = colors[i]\n",
    "    return color_label\n",
    "\n",
    "def plot_image(img, label=None, save_file='image.png', alpha=0.3):\n",
    "    # if img is tensor, convert to cv2 image\n",
    "    if torch.is_tensor(img):\n",
    "        img = img.mul(255.0).cpu().numpy().transpose(1, 2, 0).astype(np.uint8)\n",
    "\n",
    "    if label is not None:\n",
    "        # if label_img is tensor, convert to cv2 image\n",
    "        if torch.is_tensor(label):\n",
    "            label = label.cpu().numpy().astype(np.uint8)\n",
    "            color_label = make_color_label(label)\n",
    "            label = color_label\n",
    "        else:\n",
    "            color_label = make_color_label(label)\n",
    "            label = color_label\n",
    "        # overlay images\n",
    "        img = cv2.addWeighted(img, 1.0, label, alpha, 0)\n",
    "    # save image\n",
    "    cv2.imwrite(save_file, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "::: {.panel-tabset}\n",
    "\n",
    "\n",
    "### <span style=\"color:sky\"> make_color_label </span>\n",
    "\n",
    "\n",
    "labelì˜ ë°ì´í„°ë¥¼ ë³´ë©´ 1024*1024 ì‚¬ì´ì¦ˆì˜ ê²€ì •ì‚¬ì§„ì´ë‹¤.<br>\n",
    "2D ë°ì´í„°ë¼ ëˆˆìœ¼ë¡œ ë³´ì´ì§€ ì•Šì§€ë§Œ ì‚¬ì§„ì•ˆì—ëŠ” 0~9ì˜ ë°ì´í„°ë¡œ ì‚¬ì§„ì´ êµ¬ì„±ë˜ì–´ìˆë‹¤. ê° ìˆ«ìì— ë§ê²Œ ìƒ‰ì„ ì¹ í•´ 3D ì»¬ëŸ¬ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ë©´ ì˜¤ë¥¸ìª½ê³¼ ê°™ì€ ê·¸ë¦¼ì´ ëœë‹¤.\n",
    "**tip** ì´ í•¨ìˆ˜ëŠ” ì‹œê°í™”ë¥¼ ìœ„í•´ ì‘ì„±ëœ í•¨ìˆ˜ì´ê³  í•™ìŠµì—ëŠ” í•„ìˆ˜ì ì¸ í•¨ìˆ˜ëŠ” ì•„ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "ë¼ë²¨ì˜ h(ë†’ì´)ì™€ w(ë„ˆë¹„)ë¥¼ ê°€ì ¸ì˜¨ë’¤ h,w,3ì˜ 0ìœ¼ë¡œëœ ë„ŒíŒŒì´ ì–´ë ˆì´ë¥¼ ë§Œë“ ë‹¤. <br>\n",
    "0ë¶€í„° 9 ìˆœì„œëŒ€ë¡œ ìƒ‰ì„ ì¹ í•œë‹¤. ìƒ‰ ì¢…ë¥˜ëŠ” colorsì™€ ê°™ì´ ì¹ í•œë‹¤.\n",
    "\n",
    ":::: {.columns}\n",
    "\n",
    "::: {.column width=\"50%\"}\n",
    "\n",
    "![ê²€ì •ìƒ‰ label íŒŒì¼](b_label.png)\n",
    "\n",
    ":::\n",
    "\n",
    "::: {.column width=\"1%\"}\n",
    ":::\n",
    "\n",
    "::: {.column width=\"49%\"}\n",
    "![ìƒ‰ì¹ í•œ label íŒŒì¼](c_label.png)\n",
    "\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    "\n",
    "\n",
    "### <span style=\"color:sky\">plot_image</span>\n",
    "\n",
    "\n",
    "1) ì…ë ¥ ì´ë¯¸ì§€ê°€ í…ì„œ í˜•ì‹ì¸ ê²½ìš° numpy ë°°ì—´ë¡œ ë³€í™˜.<br>\n",
    "2) ë ˆì´ë¸”ì´ ì£¼ì–´ì§„ ê²½ìš° ì´ë¥¼ ì»¬ëŸ¬ ì´ë¯¸ì§€ë¡œ ë³€í™˜.<br>\n",
    "3) ì›ë³¸ ì´ë¯¸ì§€ì™€ ë ˆì´ë¸” ì´ë¯¸ì§€ë¥¼ ì˜¤ë²„ë ˆì´.<br>\n",
    "4) ìµœì¢… ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥.<br>\n",
    "\n",
    "![overlayëœ ì´ë¯¸ì§€](ovlay.png)\n",
    "\n",
    "\n",
    "<ì‚¬ìš©ëœ í•µì‹¬í•¨ìˆ˜>\n",
    "``` python\n",
    "cv2.addWeighted(src1, alpha, src2, beta, gamma)\n",
    "```\n",
    "```\n",
    "src1: ì²« ë²ˆì§¸ ì…ë ¥ ì´ë¯¸ì§€.\n",
    "alpha: ì²« ë²ˆì§¸ ì´ë¯¸ì§€ì˜ ê°€ì¤‘ì¹˜.\n",
    "src2: ë‘ ë²ˆì§¸ ì…ë ¥ ì´ë¯¸ì§€.\n",
    "beta: ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ì˜ ê°€ì¤‘ì¹˜.\n",
    "gamma: ê²°ê³¼ ì´ë¯¸ì§€ì— ë”í•  ê°€ì¤‘ì¹˜ ê°’\n",
    "```\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrix:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.confusion_matrix = np.zeros((num_classes, num_classes))\n",
    "        \n",
    "    def process_batch(self, preds, targets):\n",
    "        targets = targets.cpu().numpy().flatten()\n",
    "        preds = preds.argmax(1).cpu().numpy().flatten()\n",
    "        mask = (targets >= 0) & (targets < self.num_classes)\n",
    "        \n",
    "        confusion_mtx = np.bincount(\n",
    "                        self.num_classes * targets[mask].astype(int) + preds[mask],\n",
    "                        minlength=self.num_classes ** 2)\n",
    "        confusion_mtx = confusion_mtx.reshape(self.num_classes, self.num_classes)\n",
    "        self.confusion_matrix += confusion_mtx\n",
    "        return confusion_mtx\n",
    "    \n",
    "    def print(self):\n",
    "        for i in range(self.num_classes):\n",
    "            print(f\"Class{i}:{self.confusion_matrix[i,i]} / {self.confusion_matrix[i].sum()}\")\n",
    "\n",
    "    def get_pix_acc(self):\n",
    "        return np.diag(self.confusion_matrix).sum() / self.confusion_matrix.sum()\n",
    "\n",
    "    def get_class_acc(self):\n",
    "        class_acc = np.diag(self.confusion_matrix) / self.confusion_matrix.sum(axis=1)\n",
    "        return np.nanmean(class_acc),class_acc\n",
    "    \n",
    "    def get_iou(self):\n",
    "        divisor = self.confusion_matrix.sum(axis=1)\\\n",
    "                    + self.confusion_matrix.sum(axis=0)\\\n",
    "                    - np.diag(self.confusion_matrix)\n",
    "        iou = np.diag(self.confusion_matrix) / divisor\n",
    "        return iou\n",
    "    \n",
    "    def get_mean_iou(self):\n",
    "        iou = self.get_iou()\n",
    "        return np.nansum(iou) / self.num_classes\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n",
    "::: {.panel-tabset}\n",
    "\n",
    "### <span style=\"color:purple\">ConfusionMatrix</span>\n",
    "\n",
    "::: {.panel-tabset}\n",
    "\n",
    "\n",
    "### <span style=\"color:sky\"> __init__ </span>\n",
    "\n",
    "``` python\n",
    "def __init__(self, num_classes):\n",
    "    self.num_classes = num_classes\n",
    "    self.confusion_matrix = np.zeros((num_classes, num_classes))\n",
    "```\n",
    "__init__ ë©”ì†Œë“œëŠ”<br>\n",
    " í´ë˜ìŠ¤ê°€ ì´ˆê¸°í™”ë  ë•Œ í´ë˜ìŠ¤ ë‚´ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ **ì¤€ë¹„ë¬¼**ì„ ì¤€ë¹„í•˜ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤.<br>\n",
    "```\n",
    "ì˜ˆì‹œ ìƒí™©\n",
    " classì˜ ìˆ˜ë¥¼ 4ì´ë¼ê³  í–ˆì„ë•Œ, 0ìœ¼ë¡œ êµ¬ì„±ëœ 4by4í–‰ë ¬ì´ ì¤€ë¹„ëœë‹¤.\n",
    "```\n",
    "\n",
    "![â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€â€np.zeros((3,3))](033.png)    \n",
    "\n",
    "### <span style=\"color:sky\">process_batch</span>\n",
    "\n",
    "``` python\n",
    "def process_batch(self, preds, targets):\n",
    "    targets = targets.cpu().numpy().flatten()\n",
    "    preds = preds.argmax(1).cpu().numpy().flatten()\n",
    "    mask = (targets >= 0) & (targets < self.num_classes)\n",
    "    \n",
    "    confusion_mtx = np.bincount(\n",
    "                    self.num_classes * targets[mask].astype(int) + preds[mask],\n",
    "                    minlength=self.num_classes ** 2)\n",
    "    confusion_mtx = confusion_mtx.reshape(self.num_classes, self.num_classes)\n",
    "    self.confusion_matrix += confusion_mtx\n",
    "```\n",
    "[ì„¤ëª…] \n",
    "\n",
    "![ì´í•´ë¥¼ ë•ê¸°ìœ„í•´ ì‚¬ì§„ì˜ targetsê³¼ predsì„ process_batchì— ì ìš©í•´ë³´ë ¤ê³  í•œë‹¤.](3by3.png)\n",
    "\n",
    "```\n",
    "maskëŠ” ì‚¬ì§„ì—ì„œ ì„¤ì •í•œ í´ë˜ìŠ¤(ì—¬ê¸°ì„œëŠ” 4ë¡œ ì„¤ì •í–ˆìœ¼ë‹ˆê¹ 0~3) ê°’ì¸ ê²ƒë§Œ ë‚¨ê¸°ê³ ,\n",
    "ê·¸ ì™¸ì˜ ê°’ì€ ì œì™¸í•˜ëŠ” ì—­í• ì„ í•œë‹¤.\n",
    "```\n",
    "\n",
    "![ì •ë‹µtraget.shape=(3,3) ì¶”ë¡ ê°’preds.shape=(3,3)ì„ flatenìœ¼ë¡œ ì¼ë ¬ë¡œ ë‚˜ì—´í•´ shapeì„ (9)ë¡œ ë§Œë“ ë‹¤.](flaten.png)\n",
    "\n",
    "![[í´ë˜ìŠ¤*ì •ë‹µ(9) + ì¶”ë¡ ê°’(9)]ì˜ ì‹ì„ ì´ìš©í•´ ì¸ë±ìŠ¤ë¥¼ ê³„ì‚°í•œë‹¤. ê²°ê³¼=> [0, 6, 10, 13, 10, 5, 0, 15, 4] ](index_cal.png)\n",
    "\n",
    "![[0, 6, 10, 13, 10, 5, 0, 15, 4]ì—ì„œ 0ì€ 2ê°œ 1ì€ 0ê°œ 15ì€ 1ê°œ ì´ëŸ°ì‹ìœ¼ë¡œ bincountë¡œ ì›ì†Œê°’ì˜ ê°¯ìˆ˜ë¥¼ ìƒŒë‹¤.<br>\n",
    "ê°¯ìˆ˜ì˜ ê²°ê³¼ê°€ [2, 0, 0, 0, 1, 1, 1, 0, 0, 0, 2, 0, 0, 1, 0, 1] ì´ë ‡ê²Œ ë‚˜ì˜¨ë‹¤. <br>\n",
    "**tip.** minlengthëŠ” ì¸ë±ìŠ¤ì˜ ë²”ìœ„ë¥¼ ë‚˜íƒ€ëƒ„ ì´ ì‹ì—ì„œëŠ” 4x4 í‘œë¥¼ ë§Œë“¤ê²ƒì´ê¸° ë•Œë¬¸ì— 4**2fë¡œ ì„¤ì •](npbincount.png)\n",
    "\n",
    "![confusion_mtx.reshape(4, 4)ë¥¼ í†µí•´ ê¸¸ì´16ë²¡í„°ë¥¼ 4by4 í–‰ë ¬ë¡œ ë³€ê²½ í›„, ë°©ê¸ˆ initì—ì„œ ë§Œë“¤ì—ˆë˜ 0ìœ¼ë¡œ êµ¬ì„±ëœ 4by4 self.confusion_matrixì— ë„£ì–´ì¤€ë‹¤.](í–‰ë ¬.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### <span style=\"color:sky\">print</span>\n",
    "\n",
    "``` python\n",
    "def print(self):\n",
    "    for i in range(self.num_classes):\n",
    "        print(f\"Class{i}:\n",
    "                {self.confusion_matrix[i,i]} / {self.confusion_matrix[i].sum()}\")\n",
    "```\n",
    "ê° í´ë˜ìŠ¤ë³„ accuracyë¥¼ í‘œí˜„ \n",
    "\n",
    "![](í–‰ë ¬.png)\n",
    "\n",
    "    Class0:2.0 / 2.0  <=ì •ë‹µ0 2ê°œ ì¤‘ 2ê°œë¥¼ ë§ì·„ì–´\n",
    "    Class1:1.0 / 3.0  <=ì •ë‹µ1 3ê°œ ì¤‘ 1ê°œë¥¼ ë§ì·„ì–´\n",
    "    Class2:2.0 / 2.0  <=ì •ë‹µ1 2ê°œ ì¤‘ 2ê°œë¥¼ ë§ì·„ì–´\n",
    "    Class3:1.0 / 2.0  <=ì •ë‹µ1 2ê°œ ì¤‘ 1ê°œë¥¼ ë§ì·„ì–´\n",
    "\n",
    "### <span style=\"color:sky\">get_pix_acc</span>\n",
    "\n",
    "``` python\n",
    "def get_pix_acc(self):\n",
    "    return np.diag(self.confusion_matrix).sum() / self.confusion_matrix.sum()\n",
    "```\n",
    "get_pix_acc ë©”ì„œë“œëŠ” í”½ì…€ ì •í™•ë„(Pixel Accuracy)ë¥¼ ê³„ì‚°í•˜ëŠ” ì—­í• <br>\n",
    "í”½ì…€ ì •í™•ë„ëŠ” ì´ë¯¸ì§€ ë¶„í• ì´ë‚˜ ë¶„ë¥˜ ì‘ì—…ì—ì„œ ì˜ˆì¸¡ëœ í”½ì…€ì´ ì‹¤ì œ ê°’ê³¼ ì¼ì¹˜í•˜ëŠ” ë¹„ìœ¨\n",
    "\n",
    "![(np.diagí–‰ë ¬ì˜ ê°€ìš´ë°ê°’ì„ ëª¨ë‘ ë”í•œê°’(6)) ë‚˜ëˆ„ê¸° (confusion_matrix.sumí–‰ë ¬ì˜ ëª¨ë“ ê°’ ë”í•œê°’(9))<br>\n",
    "get_pix_accë‹µ : 6/9    ](í–‰ë ¬.png)\n",
    "\n",
    "### <span style=\"color:sky\">get_class_acc</span>\n",
    "\n",
    "``` python\n",
    "def get_class_acc(self):\n",
    "    class_acc =np.diag(self.confusion_matrix) / self.confusion_matrix.sum(axis=1)\n",
    "    return np.nanmean(class_acc),class_acc\n",
    "```\n",
    "\n",
    "ë„ë¡œ ì¢…ë¥˜(í´ë˜ìŠ¤)ê°€ ë¹„í¬ì¥ë„ë¡œ êµ­ë„ ê³ ì†ë„ë¡œë¡œ 3ê°œì˜ í´ë˜ìŠ¤ê°€ ìˆë‹¤ê³  í•˜ì\n",
    "ë„ì‹¬ì—ì„œ ë„ë¡œíƒì§€ë¥¼ í•œ ë’¤ í‰ê°€í•˜ë ¤ê³  í•˜ë©´ ë„ì‹œì— ë¹„í¬ì¥ë„ë¡œê°€ ì—†ê¸°ì— accuracyë¥¼ êµ¬í•˜ë©´ \n",
    "ë¹„í¬ì¥ë„ë¡œì˜ í´ë˜ìŠ¤ëŠ” 0(Nan)ê°’ì´ ë‚˜ì˜¤ê³  ì „ì²´ì  accuracyê°€ ê°ì†Œí•  ê²ƒì´ë‹¤. ì´ê²ƒì„ ë°©ì§€í•˜ê¸°\n",
    "ìœ„í•´ì„œ get_class_accì„ ì“°ëŠ”ê²ƒì´ë‹¤. ë°©ë²•ì€ np.nanmean()ì„ ì“°ë©´ ëœë‹¤.\n",
    "\n",
    "\n",
    "\n",
    "### <span style=\"color:sky\">get_iou</span>\n",
    "\n",
    "``` python\n",
    "def get_iou(self):\n",
    "    divisor = self.confusion_matrix.sum(axis=1)\\\n",
    "                + self.confusion_matrix.sum(axis=0)\\\n",
    "                - np.diag(self.confusion_matrix)\n",
    "    iou = np.diag(self.confusion_matrix) / divisor\n",
    "    return iou\n",
    "```\n",
    "\n",
    "ê° í´ë˜ìŠ¤ë³„ iouë¥¼ êµ¬í•˜ëŠ” ì½”ë“œì´ë‹¤. ì¶œë ¥ê°’ì€ ë‹¤ìŒê³¼ ê°™ì´ ë‚˜ì˜¨ë‹¤.<br>\n",
    "    >>IoU: [0.66666667 0.25 0.66666667 0.5 ]\n",
    "\n",
    ":::: {.columns}\n",
    "::: {.column width=\"45%\"}\n",
    "![iou 0.39 ì˜ˆì‹œ](iou1.png) \n",
    "    \n",
    ":::\n",
    "\n",
    "::: {.column width=\"40%\"}\n",
    "\n",
    "![iouëŠ” Combined Regionë¶€ë¶„ ë‚˜ëˆ„ê¸° Overlapping ì´ë‹¤. ](myiou.png)\n",
    ":::\n",
    "IOUëŠ” ì˜ˆì¸¡í•œ í”½ì…€ê³¼ ì‹¤ì œ í”½ì…€ê°„ ê²¹ì¹¨ ì •ë„ë¥¼ í‰ê°€í•˜ëŠ” ì§€í‘œì´ë‹¤. <br>\n",
    "ì‚¬ëŒì´ ëˆˆìœ¼ë¡œ í‰ê°€í•˜ëŠ” ì§€í‘œì™€ ê°€ì¥ ìœ ì‚¬í•œ ì§€í‘œì´ë‹¤. <br>\n",
    "ì£¼ë¡œ ê°ì²´ ì¸ì‹ ì•Œê³ ë¦¬ì¦˜ì˜ ì •í™•ë„ë¥¼ í‰ê°€í•˜ëŠ”ë° ì‚¬ìš©ëœë‹¤.<br>\n",
    "::::\n",
    "\n",
    "\n",
    "### <span style=\"color:sky\">get_mean_iou</span>\n",
    "\n",
    "``` python\n",
    "    def get_mean_iou(self):\n",
    "        iou = self.get_iou()\n",
    "        return np.nansum(iou) / self.num_classes\n",
    "```\n",
    "\n",
    "get_iouì˜ í‰ê· ê°’ì´ë‹¤. <br>\n",
    "ì‚¬ì§„ì— í¬í•¨ë˜ì§€ ì•Šì€ í´ë˜ìŠ¤ê°€ ìˆì„ ê²½ìš° iouê°’ì´ Nanê°’ìœ¼ë¡œ ë‚˜ì˜¤ê²Œ ëœë‹¤. <br>\n",
    "Nanê°’ì„ ì œê±°í•˜ê³  ì •í™•í•œ í‰ê·  ê³„ì‚°ì„ ìœ„í•´ np.nansum()ìœ¼ë¡œ ë”í•´ì¤€ë‹¤.\n",
    "\n",
    ":::\n",
    "### <span style=\"color:purple\">ì‚¬ìš©ì˜ˆì‹œ</span>\n",
    "\n",
    "``` python\n",
    "ex_targets=torch.Tensor([[[0,1,2],[3,2,1],[0,3,1]]])#shape=(1,3,3)=(batchsize,H,W)\n",
    "ex_preds=torch.Tensor([[[[1,0,0], \n",
    "                     [0,0,0],\n",
    "                     [1,0,1]],\n",
    "                    [[0,0,0],\n",
    "                     [1,0,1],\n",
    "                     [0,0,0]],\n",
    "                    [[0,1,1],\n",
    "                     [0,1,0],\n",
    "                     [0,0,0]],\n",
    "                    [[0,0,0],\n",
    "                     [0,0,0],\n",
    "                     [0,1,0]]]]) #shape=(1,4,3,3)=(batchsize,C,H,W)\n",
    "\n",
    "\n",
    "# ConfusionMatrix í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤í™”\n",
    "num_classes = 4  # 0 ~ 10 ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ì´ 11ê°œì˜ í´ë˜ìŠ¤\n",
    "confusion_matrix = ConfusionMatrix(num_classes)\n",
    "\n",
    "# ë°°ì¹˜ ì²˜ë¦¬\n",
    "confusion_matrix.process_batch(ex_preds, ex_targets)\n",
    "\n",
    "# ë©”íŠ¸ë¦­ ì¶œë ¥\n",
    "confusion_matrix.print()\n",
    "print(\"process_batch:\", confusion_matrix.process_batch(ex_preds, ex_targets))\n",
    "print(\"Pixel Accuracy:\", confusion_matrix.get_pix_acc())\n",
    "print(\"Class Accuracy:\", confusion_matrix.get_class_acc())\n",
    "print(\"IoU:\", confusion_matrix.get_iou())\n",
    "print(\"Mean IoU:\", confusion_matrix.get_mean_iou())\n",
    "```\n",
    ":::: {.columns}\n",
    "::: {.column width=\"60%\"}\n",
    "    ê²°ê³¼\n",
    "    Class0:2.0 / 2.0  <=ì •ë‹µ0 2ê°œ ì¤‘ 2ê°œë¥¼ ë§ì·„ì–´\n",
    "    Class1:1.0 / 3.0  <=ì •ë‹µ1 3ê°œ ì¤‘ 1ê°œë¥¼ ë§ì·„ì–´\n",
    "    Class2:2.0 / 2.0  <=ì •ë‹µ1 2ê°œ ì¤‘ 2ê°œë¥¼ ë§ì·„ì–´\n",
    "    Class3:1.0 / 2.0  <=ì •ë‹µ1 2ê°œ ì¤‘ 1ê°œë¥¼ ë§ì·„ì–´\n",
    "    process_batch:\n",
    "    [[2 0 0 0]\n",
    "    [1 1 1 0]\n",
    "    [0 0 2 0]\n",
    "    [0 1 0 1]]\n",
    "    Pixel Accuracy: 0.6666\n",
    "    Class Accuracy: 0.7083\n",
    "    IoU: [0.66666667 0.25 0.66666667 0.5 ]\n",
    "    Mean IoU: 0.52083\n",
    "    \n",
    ":::\n",
    "\n",
    "::: {.column width=\"40%\"}\n",
    "\n",
    "![](3by3.png)\n",
    "\n",
    "\n",
    "\n",
    "![](í–‰ë ¬.png)\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    "::::\n",
    "\n",
    "\n",
    "\n",
    ":::\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bce_loss(preds, targets, pos_weight=None):\n",
    "    bce_loss = F.binary_cross_entropy_with_logits(\n",
    "        preds.float(),\n",
    "        targets.float(),\n",
    "        pos_weight=pos_weight,\n",
    "    )\n",
    "    return bce_loss\n",
    "\n",
    "\n",
    "def ce_loss(preds, targets, ignore=255):\n",
    "    ce_loss = F.cross_entropy(\n",
    "        preds.float(),\n",
    "        targets.long(),    # [B, H, W]\n",
    "        ignore_index=ignore,\n",
    "    )\n",
    "    return ce_loss\n",
    "\n",
    "\n",
    "def dice_loss(preds, targets, eps=1e-7):\n",
    "    num_classes = preds.shape[1]\n",
    "    true_1_hot = F.one_hot(targets.squeeze(1), num_classes=num_classes)   # (B, 1, H, W) to (B, H, W, C)\n",
    "    true_1_hot = true_1_hot.permute(0, 3, 1, 2)                        # (B, H, W, C) to (B, C, H, W)\n",
    "    probas = F.softmax(preds, dim=1)\n",
    "    true_1_hot = true_1_hot.type(preds.type()).contiguous()\n",
    "    dims = (0,) + tuple(range(2, targets.ndimension()))        # dims = (0, 2, 3)\n",
    "    intersection = torch.sum(probas * true_1_hot, dims)     # intersection w.r.t. the class\n",
    "    cardinality = torch.sum(probas + true_1_hot, dims)      # cardinality w.r.t. the class\n",
    "    dice_loss = (2. * intersection / (cardinality + eps)).mean()\n",
    "    return (1 - dice_loss)\n",
    "\n",
    "\n",
    "def jaccard_loss(preds, targets, eps=1e-7):\n",
    "    \"\"\"Computes the Jaccard loss.\n",
    "    Args:\n",
    "    preds(logits) a tensor of shape [B, C, H, W]\n",
    "    targets: a tensor of shape [B, 1, H, W].\n",
    "    eps: added to the denominator for numerical stability.\n",
    "    Returns:\n",
    "        Jaccard loss\n",
    "    \"\"\"\n",
    "    num_classes = preds.shape[1]\n",
    "    true_1_hot = F.one_hot(targets.squeeze(1), num_classes=num_classes)  # (B, 1, H, W) to (B, H, W, C)\n",
    "    true_1_hot = true_1_hot.permute(0, 3, 1, 2)  # (B, H, W, C) to (B, C, H, W)\n",
    "    probas = F.softmax(preds, dim=1)\n",
    "    true_1_hot = true_1_hot.type(preds.type()).contiguous()\n",
    "    dims = (0,) + tuple(range(2, targets.ndimension()))\n",
    "    intersection = torch.sum(probas * true_1_hot, dims)\n",
    "    cardinality = torch.sum(probas + true_1_hot, dims)\n",
    "    union = cardinality - intersection\n",
    "    jacc_loss = (intersection / (union + eps)).mean()\n",
    "    return (1 - jacc_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.panel-tabset}\n",
    "\n",
    "\n",
    "### <span style=\"color:sky\"> bce_loss </span>\n",
    "\n",
    "``` yaml\n",
    "ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ ì´ì§„ êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤ì„ ê³„ì‚°\n",
    "Args:\n",
    "    targets: [B, 1, H, W] í˜•íƒœì˜ í…ì„œ. ì‹¤ì œ ê°’ (ë ˆì´ë¸”).\n",
    "    preds: [B, 1, H, W] í˜•íƒœì˜ í…ì„œ. ëª¨ë¸ì˜ ì˜ˆì¸¡ ê°’.\n",
    "    pos_weight: ì–‘ì„± í´ë˜ìŠ¤ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ (ì„ íƒ ì‚¬í•­).\n",
    "\n",
    "Returns:\n",
    "    bce_loss: ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ ì´ì§„ êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤.\n",
    "```\n",
    "\n",
    "![BCE LOSS](BCE.png)\n",
    "\n",
    "* N: ë°ì´í„°ì˜ ìˆ˜\n",
    "* yğ‘–ğ‘ : ì‹¤ì œ ë ˆì´ë¸” (0 ë˜ëŠ” 1)\n",
    "* pğ‘–ğ‘ : ëª¨ë¸ì´ ì˜ˆì¸¡í•œ í´ë˜ìŠ¤ 1ì— ì†í•  í™•ë¥  \n",
    "\n",
    "ëª©ì : BCEì˜ ì£¼ëœ ëª©ì ì€ ì´ì§„ ë¶„ë¥˜ ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ ğ‘ğ‘–ê°€ ì‹¤ì œ ë ˆì´ë¸” ğ‘¦ğ‘–ì™€ ì–¼ë§ˆë‚˜ ì˜ ì¼ì¹˜í•˜ëŠ”ì§€ë¥¼ ì¸¡ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ ì†ì‹¤ í•¨ìˆ˜ëŠ” ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œ ë ˆì´ë¸” ê°„ì˜ ì°¨ì´ë¥¼ ìµœì†Œí™”í•˜ë„ë¡ ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤.\n",
    "\n",
    "ì†ì‹¤ ê³„ì‚°: BCEëŠ” ê° ë°ì´í„° í¬ì¸íŠ¸ì— ëŒ€í•´ ì˜ˆì¸¡ê°’ ğ‘ğ‘–ê°€ ì‹¤ì œ ë ˆì´ë¸” ğ‘¦ğ‘–ì™€ ì–¼ë§ˆë‚˜ ë¹„ìŠ·í•œì§€ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤. ì˜ˆì¸¡ê°’ì´ ì‹¤ì œ ë ˆì´ë¸”ê³¼ ì •í™•íˆ ì¼ì¹˜í•  ë•Œ ì†ì‹¤ì€ 0ì´ ë˜ê³ , ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì†ì‹¤ì´ ì¦ê°€í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì´ ë” ì •í™•í•œ ì˜ˆì¸¡ì„ í•˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.\n",
    "\n",
    "í™•ë¥ ì  í•´ì„: BCEëŠ” ê° ì˜ˆì¸¡ê°’ ğ‘ğ‘–ì„ í´ë˜ìŠ¤ 1ì— ì†í•  í™•ë¥ ë¡œ í•´ì„í•˜ë©°, ì´ë¥¼ ë¡œê·¸ í•¨ìˆ˜ë¥¼ í†µí•´ ì†ì‹¤ì„ ê³„ì‚°í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ëª¨ë¸ì€ í´ë˜ìŠ¤ 1ì— ì†í•  í™•ë¥ ì„ ì •í™•íˆ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµë©ë‹ˆë‹¤.\n",
    "\n",
    "ìµœì í™”: BCEëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì´ì§„ ë¶„ë¥˜ ëª¨ë¸ì˜ ì†ì‹¤ í•¨ìˆ˜ë¡œ ì‚¬ìš©ë˜ë©°, ê²½ì‚¬ í•˜ê°•ë²•ì„ í†µí•´ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•˜ì—¬ ì†ì‹¤ì„ ìµœì†Œí™”í•˜ë„ë¡ í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ëª¨ë¸ì´ ë°ì´í„°ì˜ íŒ¨í„´ì„ í•™ìŠµí•˜ê³ , ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´ ì •í™•í•œ ì˜ˆì¸¡ì„ í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n",
    "\n",
    "### <span style=\"color:sky\">ce_loss</span>\n",
    "\n",
    "``` yaml\n",
    "ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ ë‹¤ì¤‘ í´ë˜ìŠ¤ êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤ì„ ê³„ì‚°\n",
    "\n",
    "Args:\n",
    "    targets: [B, H, W] í˜•íƒœì˜ í…ì„œ. ì‹¤ì œ ê°’ (ë ˆì´ë¸”).\n",
    "    preds: [B, C, H, W] í˜•íƒœì˜ í…ì„œ. ëª¨ë¸ì˜ ì˜ˆì¸¡ ê°’.\n",
    "    ignore: ë¬´ì‹œí•  í´ë˜ìŠ¤ ì¸ë±ìŠ¤.\n",
    "\n",
    "Returns:\n",
    "    ce_loss: ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ ë‹¤ì¤‘ í´ë˜ìŠ¤ êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤.\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "![CE LOSS](CE.png)\n",
    "\n",
    "* N: ë°ì´í„°ì˜ ìˆ˜\n",
    "* C: í´ë˜ìŠ¤ì˜ ìˆ˜\n",
    "* yğ‘–ğ‘ : ë°ì´í„° í¬ì¸íŠ¸ iì˜ ì‹¤ì œ í´ë˜ìŠ¤ ğ‘ì— ëŒ€í•œ one-hot ì¸ì½”ë”©ëœ ë ˆì´ë¸” (0 ë˜ëŠ” 1)\n",
    "* pğ‘–ğ‘ : ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ë°ì´í„° í¬ì¸íŠ¸ ğ‘–ê°€ í´ë˜ìŠ¤ cì— ì†í•  í™•ë¥  \n",
    "\n",
    "ëª©ì : CE ì†ì‹¤ í•¨ìˆ˜ëŠ” ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ëª¨ë¸ì—ì„œ ì˜ˆì¸¡ê°’ picê°€ ì‹¤ì œ ë ˆì´ë¸”yicì™€ ì–¼ë§ˆë‚˜ ì¼ì¹˜í•˜ëŠ”ì§€ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤. ëª¨ë¸ì´ ë‹¤ì–‘í•œ í´ë˜ìŠ¤ë¥¼ ë¶„ë¥˜í•˜ê³ , ê° í´ë˜ìŠ¤ì— ì†í•  í™•ë¥ ì„ ì •í™•í•˜ê²Œ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµì‹œí‚¤ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì†ì‹¤ ê³„ì‚°: ê° ë°ì´í„° í¬ì¸íŠ¸ì— ëŒ€í•´ CEëŠ” ê° í´ë˜ìŠ¤ì— ëŒ€í•´ ì˜ˆì¸¡ëœ í™•ë¥  picê°€ ì‹¤ì œ ë ˆì´ë¸” yic ì‚¬ì´ì˜ êµì°¨ ì—”íŠ¸ë¡œí”¼ë¥¼ ê³„ì‚°í•˜ì—¬ ì „ì²´ ë°ì´í„°ì…‹ì— ëŒ€í•œ í‰ê·  ì†ì‹¤ì„ ê³„ì‚°í•©ë‹ˆë‹¤. ì´ ì†ì‹¤ì€ ëª¨ë¸ì´ ì˜ˆì¸¡ì„ í–¥ìƒì‹œí‚¤ê³ , ë‹¤ì–‘í•œ í´ë˜ìŠ¤ ê°„ì˜ ê²°ì • ê²½ê³„ë¥¼ ëª…í™•í•˜ê²Œ ë§Œë“¤ë„ë¡ ë•ìŠµë‹ˆë‹¤.\n",
    "\n",
    "í™•ë¥ ì  í•´ì„: CE ì†ì‹¤ í•¨ìˆ˜ëŠ” ì˜ˆì¸¡ëœ í™•ë¥  picì„ í´ë˜ìŠ¤ cì— ì†í•  í™•ë¥ ë¡œ í•´ì„í•˜ë©°, ì´ë¥¼ ë¡œê·¸ í•¨ìˆ˜ë¥¼ í†µí•´ ì†ì‹¤ì„ ê³„ì‚°í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ëª¨ë¸ì€ ê° ë°ì´í„° í¬ì¸íŠ¸ê°€ ê° í´ë˜ìŠ¤ì— ì†í•  ê°€ëŠ¥ì„±ì„ ì •í™•íˆ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµë©ë‹ˆë‹¤.\n",
    "\n",
    "ìµœì í™”: CE ì†ì‹¤ í•¨ìˆ˜ëŠ” ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ë¬¸ì œì—ì„œ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ëŠ” ë° ì£¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤. ê²½ì‚¬ í•˜ê°•ë²•ì„ í†µí•´ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•˜ì—¬ CE ì†ì‹¤ì„ ìµœì†Œí™”í•˜ë„ë¡ í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### <span style=\"color:sky\">dice_loss</span>\n",
    "\n",
    "``` yaml\n",
    "SÃ¸rensenâ€“Dice ì†ì‹¤ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "\n",
    "Args:\n",
    "    preds(logits): [B, C, H, W] í˜•íƒœì˜ í…ì„œ. ëª¨ë¸ì˜ ì˜ˆì¸¡ ê°’ (ë¡œì§“).\n",
    "    targets: [B, 1, H, W] í˜•íƒœì˜ í…ì„œ. ì‹¤ì œ ê°’ (ë ˆì´ë¸”).\n",
    "    eps: ë¶„ëª¨ì— ë”í•´ì§€ëŠ” ì‘ì€ ê°’ìœ¼ë¡œ, ìˆ˜ì¹˜ì  ì•ˆì •ì„±ì„ ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "\n",
    "Returns:\n",
    "    dice_loss: SÃ¸rensenâ€“Dice ì†ì‹¤ ê°’.\n",
    "```\n",
    "\n",
    "![DICE LOSS](DICE1.png)\n",
    "\n",
    "* âˆ£Pâˆ©Tâˆ£: ì˜ˆì¸¡ëœ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì˜ì—­ Pê³¼ ì‹¤ì œ íƒ€ê²Ÿ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì˜ì—­ Tì˜ êµì§‘í•©ì˜ í¬ê¸°ì…ë‹ˆë‹¤.\n",
    "\n",
    "* âˆ£Pâˆ£: ì˜ˆì¸¡ëœ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì˜ì—­ Pì˜ í¬ê¸° ë˜ëŠ” ì›ì†Œ ìˆ˜ì…ë‹ˆë‹¤.\n",
    "\n",
    "* âˆ£Tâˆ£: ì‹¤ì œ íƒ€ê²Ÿ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì˜ì—­ Tì˜ í¬ê¸° ë˜ëŠ” ì›ì†Œ ìˆ˜ì…ë‹ˆë‹¤.\n",
    "\n",
    "ëª©ì : Dice ê³„ìˆ˜ëŠ” ë‘ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì˜ì—­ì˜ ì¤‘ì²© ì •ë„ë¥¼ ì¸¡ì •í•˜ì—¬ ì˜ˆì¸¡ëœ ì„¸ê·¸ë©˜í…Œì´ì…˜ ğ‘ƒì´ ì‹¤ì œ íƒ€ê²Ÿ ì„¸ê·¸ë©˜í…Œì´ì…˜ Tê³¼ ì–¼ë§ˆë‚˜ ì¼ì¹˜í•˜ëŠ”ì§€ë¥¼ í‰ê°€í•©ë‹ˆë‹¤. ì´ ì§€í‘œëŠ” 0ì—ì„œ 1 ì‚¬ì´ì˜ ê°’ì„ ê°€ì§€ë©°, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë‘ ì˜ì—­ì´ ì™„ì „íˆ ì¼ì¹˜í•¨ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
    "\n",
    "ê³„ì‚° ë°©ë²•: Dice ê³„ìˆ˜ì˜ ë¶„ì 2Ã—âˆ£ğ‘ƒâˆ©ğ‘‡âˆ£ëŠ” ì˜ˆì¸¡ëœ ì˜ì—­ê³¼ ì‹¤ì œ íƒ€ê²Ÿ ì˜ì—­ì˜ êµì§‘í•©ì˜ í¬ê¸°ë¥¼ ë‘ ë°°ë¡œ í™•ì¥í•˜ì—¬, under-segmentationê³¼ over-segmentationì„ ëª¨ë‘ ê³µí‰í•˜ê²Œ íŒ¨ë„í‹°ë¥¼ ì¤ë‹ˆë‹¤. ë¶„ëª¨ âˆ£Pâˆ£+âˆ£Tâˆ£ëŠ” ë‘ ì˜ì—­ì˜ í¬ê¸° í•©ìœ¼ë¡œ ì •ê·œí™”í•˜ì—¬ ê³„ìˆ˜ê°€ [0, 1] ë²”ìœ„ ë‚´ì— ìœ ì§€ë˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì‘ìš©: Dice ê³„ìˆ˜ëŠ” ì£¼ë¡œ ì˜ë£Œ ì´ë¯¸ì§€ ë¶„ì„ ë° ë‹¤ì–‘í•œ ì˜ìƒ ì²˜ë¦¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤. ì´ë¯¸ì§€ ì„¸ë¶„í™” ì•Œê³ ë¦¬ì¦˜ì˜ ì •í™•ë„ë¥¼ í‰ê°€í•˜ê³ , ì˜ˆì¸¡ëœ ì„¸ê·¸ë©˜í…Œì´ì…˜ì˜ ì§ˆì„ ë¹„êµí•˜ëŠ” ë° ì¤‘ìš”í•œ ì§€í‘œ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "\n",
    "### <span style=\"color:sky\">jaccard_loss</span>\n",
    "\n",
    "``` yaml\n",
    "    Jaccard ì†ì‹¤ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "    ì¸ìˆ˜:\n",
    "    preds(logits): í˜•ìƒì´ [B, C, H, W]ì¸ í…ì„œ\n",
    "    targets: í˜•ìƒì´ [B, 1, H, W]ì¸ í…ì„œ\n",
    "    eps: ìˆ˜ì¹˜ ì•ˆì •ì„±ì„ ìœ„í•´ ë¶„ëª¨ì— ì¶”ê°€ë˜ëŠ” ì‘ì€ ê°’\n",
    "    ë°˜í™˜:\n",
    "    Jaccard ì†ì‹¤\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "![JACCARD LOSS](JACCARD.png)\n",
    "\n",
    "* âˆ£Pâˆ©Tâˆ£: ì˜ˆì¸¡ëœ ì˜ì—­ ğ‘ƒê³¼ ì‹¤ì œ íƒ€ê²Ÿ ì˜ì—­ ğ‘‡ì˜ êµì§‘í•©ì˜ í¬ê¸°\n",
    "* âˆ£PâˆªTâˆ£: ì˜ˆì¸¡ëœ ì˜ì—­ ğ‘ƒê³¼ ì‹¤ì œ íƒ€ê²Ÿ ì˜ì—­ ğ‘‡ì˜ í•©ì§‘í•©ì˜ í¬ê¸°\n",
    "\n",
    "ëª©ì : Jaccard ì§€ìˆ˜ëŠ” ë‘ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì˜ì—­ì˜ ì¤‘ì²© ì •ë„ë¥¼ ì¸¡ì •í•˜ì—¬ ì˜ˆì¸¡ëœ ì„¸ê·¸ë©˜í…Œì´ Pì´ ì‹¤ì œ íƒ€ê²Ÿ ì„¸ê·¸ë©˜í…Œì´ì…˜ Tê³¼ ì–¼ë§ˆë‚˜ ì¼ì¹˜í•˜ëŠ”ì§€ë¥¼ í‰ê°€í•©ë‹ˆë‹¤. ì´ ì§€í‘œëŠ” 0ì—ì„œ 1 ì‚¬ì´ì˜ ê°’ì„ ê°€ì§€ë©°, 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë‘ ì˜ì—­ì´ ì™„ì „íˆ ì¼ì¹˜í•¨ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
    "\n",
    "ê³„ì‚° ë°©ë²•: Jaccard ì§€ìˆ˜ëŠ” ì˜ˆì¸¡ëœ ì˜ì—­ ğ‘ƒê³¼ ì‹¤ì œ íƒ€ê²Ÿ ì˜ì—­ ğ‘‡ì˜ êµì§‘í•© í¬ê¸°ë¥¼ ë‘ ì˜ì—­ì˜ í•©ì§‘í•© í¬ê¸°ë¡œ ë‚˜ëˆ„ì–´ ê³„ì‚°í•©ë‹ˆë‹¤. ì´ëŠ” ë‘ ì˜ì—­ì´ ì–¼ë§ˆë‚˜ ê²¹ì¹˜ëŠ”ì§€ë¥¼ í‰ê°€í•˜ë©°, ë¶„ìëŠ” êµì§‘í•©ì˜ í¬ê¸°ë¥¼ ë‚˜íƒ€ë‚´ê³  ë¶„ëª¨ëŠ” ì „ì²´ì ì¸ ì˜ˆì¸¡ëœ ì˜ì—­ê³¼ ì‹¤ì œ íƒ€ê²Ÿ ì˜ì—­ì˜ í¬ê¸°ë¥¼ ë°˜ì˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì‘ìš©: Jaccard ì§€ìˆ˜ëŠ” ì£¼ë¡œ ì´ë¯¸ì§€ ì„¸ë¶„í™”ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ì²˜ë¦¬ ë° íŒ¨í„´ ì¸ì‹ ë¬¸ì œì—ì„œ ìœ ì‚¬ì„±ì„ ë¹„êµí•˜ê³  ëª¨ë¸ì˜ ì •í™•ë„ë¥¼ í‰ê°€í•˜ëŠ” ë° ì¤‘ìš”í•œ ì§€í‘œë¡œ í™œìš©ë©ë‹ˆë‹¤.\n",
    ":::\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one_epoch( train, val )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(train_dataloader, model, optimizer, device):\n",
    "    model.train()\n",
    "    losses = [] \n",
    "    for i, (imgs, targets, _) in enumerate(train_dataloader):\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "        preds = model(imgs)['out']     # forward \n",
    "        loss = ce_loss(preds, targets) # calculates the iteration loss  \n",
    "        optimizer.zero_grad()   # zeros the parameter gradients\n",
    "        loss.backward()         # backward\n",
    "        optimizer.step()        # update weights\n",
    "        print('\\t iteration: %d/%d, loss=%.4f' % (i, len(train_dataloader)-1, loss))    \n",
    "        losses.append(loss.item())\n",
    "    return torch.tensor(losses).mean().item()\n",
    "\n",
    "\n",
    "def val_one_epoch(val_dataloader, model, confusion_matrix, device):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for i, (imgs, targets, img_file) in enumerate(val_dataloader):\n",
    "        imgs, targets = imgs.to(device), targets.to(device)\n",
    "        with torch.no_grad():\n",
    "            preds = model(imgs)['out']   # forward, preds: (B, 2, H, W)\n",
    "            loss = ce_loss(preds, targets)\n",
    "            losses.append(loss.item())\n",
    "            confusion_matrix.process_batch(preds, targets)\n",
    "            # sample images\n",
    "            if i == 0:\n",
    "                preds = torch.argmax(preds, axis=1) # (1, H, W)  \n",
    "                for j in range(3):\n",
    "                    save_file = os.path.join('outputs', 'val_%d.png' % (j))\n",
    "                    plot_image(imgs[j], preds[j], save_file)\n",
    "                \n",
    "    avg_loss = torch.tensor(losses).mean().item()\n",
    "    \n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.panel-tabset}\n",
    "\n",
    "### <span style=\"color:sky\">train_one_epoch</span>\n",
    "```\n",
    "1) def train_one_epoch(train_dataloader, model, optimizer, device)ì´ë¼ëŠ”\n",
    "    í•¨ìˆ˜ëŠ” íŒŒë¼ë¯¸í„°ê°€ 4ê°œì´ë‹¤.\n",
    "2) model.train()ì€ í•™ìŠµëª¨ë“œì¸ê²ƒì„ ë‚˜íƒ€ë‚¸ë‹¤.\n",
    "3) losses = []ëŠ” trainì˜ lossê°’ì„ ì €ì¥í•˜ê¸° ìœ„í•¨ì´ë‹¤.\n",
    "4) ë°˜ë³µë¬¸(for)ì˜ i ëŠ” enumerateí•¨ìˆ˜ì—ì„œ ë§Œë“¤ì–´ì§„(ì¸ë±ì‹±ëœ) 0ë¶€í„° nê¹Œì§€ì˜\n",
    "    ìˆ«ìì´ê³  (imgs, targets, _)ëŠ” ê°ê° imgsëŠ” ìœ„ì„±ì‚¬ì§„ targetsëŠ” ì •ë‹µë¼ë²¨ì´ë‹¤.\n",
    "5) deviceë¥¼ í†µí•´ cpuì—ì„œ gpuë¡œ ì´ë™ì‹œí‚¤ëŠ” ê³¼ì •ìœ¼ë¡œ deviceëŠ” ë’¤ì—ì„œ ì •ì˜í•  ê²ƒì´ë‹¤.\n",
    "6) modelì— imgë¥¼ ì§‘ì–´ë„£ì–´ predsë¥¼ ì˜ˆì¸¡í•´ë³¸ë‹¤. ì´ë•Œ [out]ì´ ë¶™ëŠ” ì´ìœ ëŠ”\n",
    "    torchvisionì— ì €ì¥ë˜ì–´ ìˆëŠ” deeplabv3ëª¨ë¸ì„ ì‚¬ìš©í• ë•Œì˜ ë°©ì‹ì´ë‹¤.\n",
    "7) lossëŠ” ì•ì—ì„œ ì •ì˜í•´ì¤€ ë¡œìŠ¤ ì¤‘ ce_lossë¥¼ ì‚¬ìš©í–ˆë‹¤. \n",
    "    ì´ë•Œ predsê°€ ë¨¼ì € ë“¤ì–´ê°€ì•¼í•˜ëŠ” ì ì„ ì£¼ì˜í•˜ì\n",
    "8) optimizer.zeroëŠ” lossì˜ ë¯¸ë¶„ê°’ì„ ê³„ì‚°í•˜ê¸°ì „ 0ìœ¼ë¡œ ì´ˆê¸°í™”í•˜ëŠ” ê³¼ì •ì´ë‹¤.\n",
    "9) loss.backward()ëŠ” lossê°’ì„ í¸ë¯¸ë¶„í•˜ëŠ” ê³¼ì •ì´ë‹¤. \n",
    "    í¸ë¯¸ë¶„ì€ 2ì°¨ì› ê³µê°„ì—ì„œ ë¯¸ë¶„ì„ í•œ ë²ˆì— ëª»í•˜ë‹ˆê¹ \n",
    "    ìˆœì°¨ì ìœ¼ë¡œ ë¯¸ë¶„í•˜ëŠ” ê³¼ì •ì´ë¼ê³  ìƒê°í•˜ë©´ ëœë‹¤.\n",
    "10) ë¯¸ë¶„í•œ ê°’ì„ ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ê°’ì— ë°˜ì˜í•œë‹¤(ë¯¸ë¶„ê°’ì„ ë¹¼ì£¼ëŠ”ê³¼ì •). \n",
    "11) iterationë³„ train lossë¥¼ í‘œì‹œí•´ì¤€ë‹¤.\n",
    "12) lossë¥¼ lossesì— ì €ì¥í•œë‹¤.\n",
    "13) returnì„ í†µí•´ í•¨ìˆ˜ ë°–ì—ì„œë„ lossesì˜ í‰ê· ì„ í˜¸ì¶œ í•  ìˆ˜ ìˆê²Œí•œë‹¤.\n",
    "```\n",
    "\n",
    "### <span style=\"color:sky\">val_one_epoch</span>\n",
    "```\n",
    "1) def val_one_epoch(val_dataloader, model, confusion_matrix, device)ì´ë¼ëŠ”\n",
    "    í•¨ìˆ˜ëŠ” íŒŒë¼ë¯¸í„°ê°€ 4ê°œì´ë‹¤.\n",
    "2) model.eval()ì€ í•™ìŠµëª¨ë“œì¸ê²ƒì„ ë‚˜íƒ€ë‚¸ë‹¤.\n",
    "3) losses = []ëŠ” validationì˜ lossê°’ì„ ì €ì¥í•˜ê¸° ìœ„í•¨ì´ë‹¤.\n",
    "4) ë°˜ë³µë¬¸(for)ì˜ i ëŠ” enumerateí•¨ìˆ˜ì—ì„œ ë§Œë“¤ì–´ì§„(ì¸ë±ì‹±ëœ) 0ë¶€í„° nê¹Œì§€ì˜\n",
    "    ìˆ«ìì´ê³  (imgs, targets, _)ëŠ” ê°ê° imgsëŠ” ìœ„ì„±ì‚¬ì§„ targetsëŠ” ì •ë‹µë¼ë²¨ì´ë‹¤.\n",
    "5) deviceë¥¼ í†µí•´ cpuì—ì„œ gpuë¡œ ì´ë™ì‹œí‚¤ëŠ” ê³¼ì •ìœ¼ë¡œ deviceëŠ” ë’¤ì—ì„œ ì •ì˜í•  ê²ƒì´ë‹¤.\n",
    "6) modelì— imgë¥¼ ì§‘ì–´ë„£ì–´ predsë¥¼ ì˜ˆì¸¡í•´ë³¸ë‹¤. ì´ë•Œ [out]ì´ ë¶™ëŠ” ì´ìœ ëŠ”\n",
    "    torchvisionì— ì €ì¥ë˜ì–´ ìˆëŠ” deeplabv3ëª¨ë¸ì„ ì‚¬ìš©í• ë•Œì˜ ë°©ì‹ì´ë‹¤.\n",
    "7) lossëŠ” ì•ì—ì„œ ì •ì˜í•´ì¤€ ë¡œìŠ¤ ì¤‘ ce_lossë¥¼ ì‚¬ìš©í–ˆë‹¤. \n",
    "    ì´ë•Œ predsê°€ ë¨¼ì € ë“¤ì–´ê°€ì•¼í•˜ëŠ” ì ì„ ì£¼ì˜í•˜ì\n",
    "8) lossë¥¼ lossesì— ì €ì¥í•œë‹¤.\n",
    "9) ì´í›„ì— ConfusionMatrixë¥¼ ì´ìš©í•´ confusion_matrixë¼ëŠ” ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë§Œë“¤ê²Œ\n",
    " ë˜ëŠ”ë° ë§Œë“¤ì–´ì§„ ì¸ìŠ¤í„´ìŠ¤ì— ëª¨ë¸ì´ ì˜ˆì¸¡í•œ predsì™€ ì •ë‹µì§€ targetsì„ ë„£ì–´ì£¼ë©´ \n",
    " í–‰ë ¬ì´ ê³„ì‚°ì´ ë¼ì„œ ì•„ë˜ì™€ ê°™ì´ ì‚¬ìš©ê°€ëŠ¥í•˜ë‹¤.\n",
    "``` \n",
    "            val_epoch_iou = confusion_matrix.get_iou()\n",
    "            val_epoch_mean_iou = confusion_matrix.get_mean_iou()\n",
    "            val_epoch_pix_accuracy = confusion_matrix.get_pix_acc() \n",
    "```\n",
    "\n",
    "12) ~ 16) i=0ì¼ë•Œ(epochì´ ìƒˆë¡œ ì‹œì‘ë ë•Œ)ë§ˆë‹¤ plot_image í•¨ìˆ˜ë¥¼ ì´ìš©í•´ \n",
    "imgì— predsë¥¼ ì˜¤ë²„ë ˆì´í•´ì„œ ì‚¬ì§„ìœ¼ë¡œ ì €ì¥í•œë‹¤.(ì´ 3ì¥ ì €ì¥í•œë‹¤.) \n",
    "ì¶”ê°€ë¡œ ì €ì¥ëœ ì‚¬ì§„ì€ ì´ë¦„ì´ val_0(1,2).pngìœ¼ë¡œ ë§¤ ì—í­ë§ˆë‹¤ ì‚¬ì§„ì´ ë°”ë€ë‹¤. \n",
    "ë”°ë¡œ ì €ì¥í•˜ë ¤ë©´ ìˆ˜ì •í•„ìš”\n",
    "17~) returnì„ í†µí•´ í•¨ìˆ˜ ë°–ì—ì„œë„ validation lossesì˜ í‰ê· ì„ í˜¸ì¶œ í•  ìˆ˜ ìˆê²Œí•œë‹¤.\n",
    "```\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def train______________________________________________________#   \n",
    "def train(epochs=200, batch_size = 8 , name = 'suwany'):\n",
    "#1______________________________________________________________#    \n",
    "    #Â wandbÂ settings\n",
    "    wandb.init(id=name, resume='allow', mode='disabled')\n",
    "    wandb.config.update({\n",
    "        'epochs': epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'name': name\n",
    "    })\n",
    "#2______________________________________________________________#   \n",
    "    # Train dataset\n",
    "    train_dataset = KariRoadDataset('./data/kari-road', train=True)\n",
    "    # Train dataloader\n",
    "    num_workers = min([os.cpu_count(), batch_size, 16])\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                            shuffle=True, num_workers=num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # Validation dataset\n",
    "    val_dataset = KariRoadDataset('./data/kari-road', train=False)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, \n",
    "                            shuffle=True, num_workers=num_workers, pin_memory=True, drop_last=False)\n",
    "#3______________________________________________________________#   \n",
    "    # Network model\n",
    "    num_classes = 10 # background + 1 classes\n",
    "    model = models.segmentation.deeplabv3_resnet101(num_classes=num_classes)  \n",
    "    \n",
    "    # GPU-support\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if torch.cuda.device_count() > 1:   # multi-GPU\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "#______________________________________________________________#   \n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "      \n",
    "    # Learning rate scheduler\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "#______________________________________________________________#   \n",
    "    # loading a weight file (if exists)\n",
    "    weight_file = Path('weights')/(name + '.pth')\n",
    "    best_accuracy = 0.0\n",
    "    start_epoch, end_epoch = (0, epochs)\n",
    "    if os.path.exists(weight_file):\n",
    "        checkpoint = torch.load(weight_file)\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_accuracy = checkpoint['best_accuracy']\n",
    "        print('resumed from epoch %d' % start_epoch)\n",
    "#______________________________________________________________#       \n",
    "    \n",
    "    confusion_matrix = ConfusionMatrix(num_classes)\n",
    " # training/validation\n",
    "    for epoch in range(start_epoch, end_epoch):\n",
    "        print('epoch: %d/%d' % (epoch, end_epoch-1))\n",
    "        t0 = time.time()\n",
    "        # training\n",
    "        epoch_loss = train_one_epoch(train_dataloader, model, optimizer, device)\n",
    "        t1 = time.time()\n",
    "        print('loss=%.4f (took %.2f sec)' % (epoch_loss, t1-t0))\n",
    "        lr_scheduler.step(epoch_loss)\n",
    "        # validation\n",
    "        val_epoch_loss = val_one_epoch(val_dataloader, model, confusion_matrix, device)\n",
    "        val_epoch_iou = confusion_matrix.get_iou()\n",
    "        val_epoch_mean_iou = confusion_matrix.get_mean_iou()\n",
    "        val_epoch_pix_accuracy = confusion_matrix.get_pix_acc()\n",
    "        \n",
    "        print('[validation] loss=%.4f, mean iou=%.4f, pixel accuracy=%.4f' % \n",
    "              (val_epoch_loss, val_epoch_mean_iou, val_epoch_pix_accuracy))\n",
    "        print('class IoU: [' + ', '.join([('%.4f' % (x)) for x in val_epoch_iou]) + ']')\n",
    "        # saving the best status into a weight file\n",
    "        if val_epoch_pix_accuracy > best_accuracy:\n",
    "             best_weight_file = Path('weights')/(name + '_best.pth')\n",
    "             best_accuracy = val_epoch_pix_accuracy\n",
    "             state = {'model': model.state_dict(), 'epoch': epoch, 'best_accuracy': best_accuracy}\n",
    "             torch.save(state, best_weight_file)\n",
    "             print('best accuracy=>saved\\n')\n",
    "        # saving the current status into a weight file\n",
    "        state = {'model': model.state_dict(), 'epoch': epoch, 'best_accuracy': best_accuracy}\n",
    "        torch.save(state, weight_file)\n",
    "        # wandb logging\n",
    "        wandb.log({'train_loss': epoch_loss, 'val_loss': val_epoch_loss, 'val_accuracy': val_epoch_pix_accuracy})\n",
    "#______________________________________________________________#          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.panel-tabset}\n",
    "\n",
    "### <span style=\"color:sky\">í•¨ìˆ˜ train ì†Œê°œ</span>\n",
    "\n",
    "ì´ í•¨ìˆ˜ëŠ” ì§€ê¸ˆê¹Œì§€ ì •ì˜í•œ í•¨ìˆ˜ë“¤ì„ ì´ìš©í•¨, ì£¼ì–´ì§„ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •ì„ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ê²€ì¦í•˜ëŠ” ê³¼ì •ì„ í¬í•¨ë˜ì–´ìˆë‹¤. ë˜í•œ, ëª¨ë¸ì˜ ìƒíƒœë¥¼ ì €ì¥í•˜ê³ , WandB(Weights and Biases)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œê·¸ë¥¼ ê¸°ë¡í•œë‹¤.\n",
    "\n",
    "\n",
    "### <span style=\"color:sky\">def train</span>\n",
    "```\n",
    "def train(epochs=200, batch_size = 8 , name = 'suwany'):\n",
    "\n",
    "```\n",
    "* epochs: í•™ìŠµí•  ì´ ì—í¬í¬ ìˆ˜ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ 200ì…ë‹ˆë‹¤.\n",
    "* batch_size: ë¯¸ë‹ˆë°°ì¹˜ì˜ í¬ê¸°ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ 8ì…ë‹ˆë‹¤.\n",
    "* name: ì‹¤í—˜ ì´ë¦„ì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ 'suwany'ì…ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "### <span style=\"color:sky\">wandb</span>\n",
    "```\n",
    "    wandb.init(id=name, resume='allow', mode='disabled')\n",
    "    wandb.config.update({\n",
    "        'epochs': epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'name': name\n",
    "    })\n",
    "```\n",
    "* WandBë¥¼ ì´ˆê¸°í™”í•˜ê³  ì„¤ì •ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ì‹¤í—˜ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ê°€ ê¸°ë¡ë©ë‹ˆë‹¤\n",
    "\n",
    "### <span style=\"color:sky\">dataset, dataloader</span>\n",
    "```\n",
    "    # Train dataset\n",
    "    train_dataset = KariRoadDataset('./data/kari-road', train=True)\n",
    "    # Train dataloader\n",
    "    num_workers = min([os.cpu_count(), batch_size, 16])\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                            shuffle=True, num_workers=num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # Validation dataset\n",
    "    val_dataset = KariRoadDataset('./data/kari-road', train=False)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, \n",
    "                            shuffle=True, num_workers=num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "```\n",
    "* KariRoadDataset í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ë° ê²€ì¦ ë°ì´í„°ì…‹ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "* ê° ë°ì´í„°ì…‹ì— ëŒ€í•´ ë°ì´í„°ë¡œë”ë¥¼ ìƒì„±í•˜ì—¬ ë°ì´í„°ë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "* num_workersëŠ” ë°ì´í„° ë¡œë”©ì„ ìœ„í•œ CPU ìŠ¤ë ˆë“œ ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "### <span style=\"color:sky\">num_classes, model, device  </span>\n",
    "```\n",
    "    num_classes = 10  # background + 9 classes\n",
    "    model = models.segmentation.deeplabv3_resnet101(num_classes=num_classes)  \n",
    "    \n",
    "    # GPU-support\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if torch.cuda.device_count() > 1:   # multi-GPU\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "```\n",
    "* num_classesë¥¼ ì„¤ì •í•˜ì—¬ ëª¨ë¸ì˜ í´ë˜ìŠ¤ ìˆ˜ë¥¼ ì •ì˜í•œë‹¤.\n",
    "    + ì—¬ê¸°ì„œëŠ” roadì˜ í´ë˜ìŠ¤ 9ê°œì— ë°°ê²½ 1ê°œë¥¼ ì¶”ê°€í•œë‹¤.\n",
    "* DeepLabV3 ëª¨ë¸ì„ ResNet-101 ë°±ë³¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ˆê¸°í™”í–ˆë‹¤.\n",
    "* ëª¨ë¸ì„ GPUë¡œ ì´ë™ì‹œí‚¤ë©°, ì—¬ëŸ¬ GPUë¥¼ ì‚¬ìš©í•  ê²½ìš° DataParallelì„ ì‚¬ìš©í•˜ë„ë¡ í–ˆë‹¤.\n",
    "\n",
    "### <span style=\"color:sky\">Optimizer,lr_scheduler </span>\n",
    "```\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "      \n",
    "    # Learning rate scheduler\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "```\n",
    "* Adam ì˜µí‹°ë§ˆì´ì €ë¥¼ ì„¤ì •í•˜ì—¬ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ ìµœì í™”í•œë‹¤.\n",
    "* í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” ê²€ì¦ ì†ì‹¤ì´ 5íšŒ ì´ìƒ ì¤„ì–´ë“¤ì§€ ì•Šì„ ë•Œ í•™ìŠµë¥ ì„ ê°ì†Œì‹œí‚¤ë„ë¡ ì„¤ì •í–ˆë‹¤.\n",
    "\n",
    "### <span style=\"color:sky\">load</span>\n",
    "```\n",
    "    weight_file = Path('weights')/(name + '.pth')\n",
    "    best_accuracy = 0.0\n",
    "    start_epoch, end_epoch = (0, epochs)\n",
    "    if os.path.exists(weight_file):\n",
    "        checkpoint = torch.load(weight_file)\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_accuracy = checkpoint['best_accuracy']\n",
    "        print('resumed from epoch %d' % start_epoch)\n",
    "\n",
    "```\n",
    "ê¸°ì¡´ì— ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì´ ìˆìœ¼ë©´ ì´ë¥¼ ë¡œë“œí•˜ì—¬ í•™ìŠµì„ ì´ì–´ì„œ ì§„í–‰í•  ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "### <span style=\"color:sky\">train_start</span>\n",
    "```\n",
    "    confusion_matrix = ConfusionMatrix(num_classes)\n",
    "    # training/validation\n",
    "    for epoch in range(start_epoch, end_epoch):\n",
    "        print('epoch: %d/%d' % (epoch, end_epoch-1))\n",
    "        t0 = time.time()\n",
    "        # training\n",
    "        epoch_loss = train_one_epoch(train_dataloader, model, optimizer, device)\n",
    "        t1 = time.time()\n",
    "        print('loss=%.4f (took %.2f sec)' % (epoch_loss, t1-t0))\n",
    "        lr_scheduler.step(epoch_loss)\n",
    "        # validation\n",
    "        val_epoch_loss = val_one_epoch(val_dataloader, model, confusion_matrix, device)\n",
    "        val_epoch_iou = confusion_matrix.get_iou()\n",
    "        val_epoch_mean_iou = confusion_matrix.get_mean_iou()\n",
    "        val_epoch_pix_accuracy = confusion_matrix.get_pix_acc()\n",
    "        \n",
    "        print('[validation] loss=%.4f, mean iou=%.4f, pixel accuracy=%.4f' % \n",
    "              (val_epoch_loss, val_epoch_mean_iou, val_epoch_pix_accuracy))\n",
    "        print('class IoU: [' + ', '.join([('%.4f' % (x)) for x in val_epoch_iou]) + ']')\n",
    "        # saving the best status into a weight file\n",
    "        if val_epoch_pix_accuracy > best_accuracy:\n",
    "             best_weight_file = Path('weights')/(name + '_best.pth')\n",
    "             best_accuracy = val_epoch_pix_accuracy\n",
    "             state = {'model': model.state_dict(), 'epoch': epoch, 'best_accuracy': best_accuracy}\n",
    "             torch.save(state, best_weight_file)\n",
    "             print('best accuracy=>saved\\n')\n",
    "        # saving the current status into a weight file\n",
    "        state = {'model': model.state_dict(), 'epoch': epoch, 'best_accuracy': best_accuracy}\n",
    "        torch.save(state, weight_file)\n",
    "        # wandb logging\n",
    "        wandb.log({'train_loss': epoch_loss, 'val_loss': val_epoch_loss, 'val_accuracy': val_epoch_pix_accuracy})\n",
    "\n",
    "```\n",
    "* forë¬¸ì„ ì´ìš©í•´ ê° ì—í¬í¬ë§ˆë‹¤ í•™ìŠµ ë° ê²€ì¦ì„ ìˆ˜í–‰í•œë‹¤.\n",
    "* train_one_epoch í•¨ìˆ˜ëŠ” í•œ ì—í¬í¬ ë™ì•ˆ í•™ìŠµì„ ìˆ˜í–‰í•˜ë©°, ì†ì‹¤ ê°’ì„ ë°˜í™˜í–ˆë‹¤.\n",
    "* ê²€ì¦ ë‹¨ê³„ì—ì„œëŠ” val_one_epoch í•¨ìˆ˜ë¥¼ í†µí•´ ê²€ì¦ ì†ì‹¤, IoU, í‰ê·  IoU, í”½ì…€ ì •í™•ë„ë¥¼ ê³„ì‚°í•œë‹¤.\n",
    "* ìµœìƒì˜ ëª¨ë¸ ìƒíƒœë¥¼ ì €ì¥í•˜ë©°, í˜„ì¬ ìƒíƒœë„ ì—í­ë§ˆë‹¤ ì €ì¥ë˜ë„ë¡ í–ˆë‹¤.\n",
    "* WandBë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ë° ê²€ì¦ ì†ì‹¤, ì •í™•ë„ë¥¼ ë¡œê¹…ë˜ì–´ ê¸°ë¡ëœë‹¤.\n",
    "\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì‹¤í–‰ ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0/199\n",
      "\t iteration: 0/142, loss=2.2205\n",
      "\t iteration: 1/142, loss=2.1528\n",
      "\t iteration: 2/142, loss=2.1019\n",
      "\t iteration: 3/142, loss=2.0039\n",
      "\t iteration: 4/142, loss=1.9516\n",
      "\t iteration: 5/142, loss=1.8579\n",
      "\t iteration: 6/142, loss=1.8787\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msuwany\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 58\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epochs, batch_size, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# training\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss=\u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m (took \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m sec)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (epoch_loss, t1\u001b[38;5;241m-\u001b[39mt0))\n",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(train_dataloader, model, optimizer, device)\u001b[0m\n\u001b[1;32m      7\u001b[0m loss \u001b[38;5;241m=\u001b[39m ce_loss(preds, targets) \u001b[38;5;66;03m# calculates the iteration loss  \u001b[39;00m\n\u001b[1;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()   \u001b[38;5;66;03m# zeros the parameter gradients\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m         \u001b[38;5;66;03m# backward\u001b[39;00m\n\u001b[1;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()        \u001b[38;5;66;03m# update weights\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m iteration: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, loss=\u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (i, \u001b[38;5;28mlen\u001b[39m(train_dataloader)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, loss))    \n",
      "File \u001b[0;32m~/anaconda3/envs/gd/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gd/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(epochs=200, batch_size = 8 , name = 'suwany')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::: {.columns}\n",
    "\n",
    "::: {.column width=\"50%\"}\n",
    "```python{.bash filename=\"í•™êµ\"}\n",
    "---\n",
    "ì „ë¶ëŒ€í•™êµ ì§€êµ¬í™˜ê²½ê³¼í•™ê³¼\n",
    "---\n",
    "```\n",
    ":::\n",
    "\n",
    "::: {.column width=\"1%\"}\n",
    ":::\n",
    "\n",
    "::: {.column width=\"49%\"}\n",
    "``` {.bash filename=\"ì´ë¦„\"}\n",
    "---\n",
    "ê¹€ìˆ˜í™˜\n",
    "---\n",
    "```\n",
    ":::\n",
    "\n",
    "::::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
